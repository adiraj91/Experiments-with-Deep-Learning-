{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import cv2;\n",
    "import matplotlib.pyplot as plt;\n",
    "import matplotlib;\n",
    "import os;\n",
    "from collections import Counter;\n",
    "import random; \n",
    "import time;\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.listdir('C:/Users/adity/Documents/Projects/')\n",
    "#Reading the data \n",
    "# os.listdir(\"C:\\\\Users\\\\adity\\\\Documents\\\\Projects\")\n",
    "\n",
    "maindir=\"C:/Users/adity/Documents/Projects/\"\n",
    "trainDir=\"train\"\n",
    "path=os.path.join(maindir,trainDir);\n",
    "X=[];\n",
    "y=[];\n",
    "for p in os.listdir(path):\n",
    "    class_val=p.split(\".\")[0];\n",
    "    img_array=cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "    new_img_array=cv2.resize(img_array,dsize=(80,240));\n",
    "#     plt.imshow(new_img_array)\n",
    "    X.append(new_img_array);\n",
    "    y.append(class_val);\n",
    "X=np.array(X).reshape(-1,80,80,3);\n",
    "X_flatten=X.reshape(X.shape[0],-1).T\n",
    "y_flatten=np.array(y)\n",
    "\n",
    "# testDir=\"test1\"\n",
    "# path=os.path.join(maindir,testDir);\n",
    "# X_test=[];\n",
    "# y_test=[];\n",
    "# #Reading the Test Data.\n",
    "# for p in os.listdir(path):\n",
    "#     class_val=p.split(\".\");\n",
    "#     img_array=cv2.imread(os.path.join(path,p),cv.IMREAD_GRAYSCALE)\n",
    "#     new_img_array=cv.resize(img_array,dsize=(80,80))\n",
    "#     X_test.append(new_img_array);\n",
    "#     y_test.append(class_val);\n",
    "# X_test=np.array(X_test).reshape(-1,80,80,1)\n",
    "# X_test_flatten=X_test.reshape(X_test.shape[0],-1).T\n",
    "# y_test=np.array(y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X in Training DataSet  (19200, 25000)\n",
      "Shape of y in Training Dataset (25000, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train=y_flatten.reshape(y_flatten.shape[0],1)\n",
    "X_train=X_flatten.copy()\n",
    "\n",
    "print('Shape of X in Training DataSet ',X_train.shape)\n",
    "print('Shape of y in Training Dataset',y_train.shape)\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Image Data Preprocessing.\n",
    "\n",
    "* Also, class cat will be assigned 1 and dog 0. ( Although I love dogs over cats ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and validation portions \n",
    "X_train=X_train/255.\n",
    "data=pd.DataFrame(X_train).T\n",
    "data.shape\n",
    "data['Class']=y_train\n",
    "data_cat=data[data['Class']=='cat'].reset_index()\n",
    "data_dog=data[data['Class']=='dog'].reset_index()\n",
    "indices=random.sample(range(12500),12500)\n",
    "data_cat_train=data_cat.iloc[indices[:11250],:]\n",
    "data_cat_validation=data_cat.iloc[indices[11250:],:]\n",
    "data_dog_train=data_dog.iloc[indices[:11250],:]\n",
    "data_dog_validation=data_dog.iloc[indices[11250:],:]\n",
    "\n",
    "# data_cat_train.shape\n",
    "data_train=pd.concat([data_cat_train,data_dog_train])\n",
    "data_validation=pd.concat([data_cat_validation,data_dog_validation])\n",
    "\n",
    "data_train=data_train.reset_index().iloc[:,1:]\n",
    "data_train['NUM_CLASS']=0\n",
    "data_train.loc[data_train['Class']=='cat','NUM_CLASS']=1\n",
    "data_train=data_train.drop(['Class','index'],axis=1)\n",
    "data_train=data_train.T\n",
    "data_validation=data_validation.reset_index().iloc[:,1:]\n",
    "data_validation['NUM_CLASS']=0\n",
    "data_validation.loc[data_validation['Class']=='cat','NUM_CLASS']=1\n",
    "data_validation=data_validation.drop(['Class','index'],axis=1)\n",
    "data_validation=data_validation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Train Shape (19201, 22500)\n",
      "Data Validation Shape (19201, 2500)\n"
     ]
    }
   ],
   "source": [
    "print('Data Train Shape',data_train.shape)\n",
    "print('Data Validation Shape',data_validation.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X,y):\n",
    "    ''' Function to set the layer sizes '''\n",
    "    n_x=X.shape[0];\n",
    "    n_h=5;\n",
    "    n_y=y.shape[0]\n",
    "    \n",
    "    return n_x,n_h,n_y;\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters (n_x,n_h,n_y):\n",
    "    ''' Initializing the parameters to random values.'''\n",
    "    W1=np.random.randn(n_h,n_x)*0.001;\n",
    "    b1=np.zeros((n_h,1));\n",
    "    W2=np.random.randn(n_y,n_h)*0.001;\n",
    "    b2=np.zeros((n_y,1));\n",
    "    \n",
    "    assert (W1.shape==(n_h,n_x))\n",
    "    assert (b1.shape==(n_h,1))\n",
    "    assert (W2.shape==(n_y,n_h))\n",
    "    assert (b2.shape==(n_y,1))\n",
    "    \n",
    "    \n",
    "    return {'W1':W1,'b1':b1,'W2':W2,'b2':b2};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid (z):\n",
    "    ''' Implementation of sigmoid '''\n",
    "    a=1/(1+np.exp(-z));\n",
    "    return a; \n",
    "\n",
    "\n",
    "def tangent_h(z):\n",
    "    '''Implementation tanh function''' \n",
    "    return np.tanh(z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 5.88794441e-04  1.62250584e-05  6.41015163e-04  7.95197898e-04\n",
      "   1.01986584e-03]\n",
      " [-4.08012014e-04  5.00426509e-04 -1.20988682e-03  1.67710125e-04\n",
      "   6.63342391e-04]\n",
      " [ 7.95612628e-04  1.93913624e-04 -1.77102281e-04  1.20272645e-03\n",
      "   2.51268387e-05]\n",
      " [ 6.36772847e-04 -3.91593012e-04  7.29299324e-04  9.40488511e-04\n",
      "  -4.16203559e-04]\n",
      " [-1.25389272e-03  1.57215672e-03  1.96739520e-03  3.15506627e-04\n",
      "  -2.03418096e-04]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[ 1.71553304e-03  1.98934321e-03  2.43623027e-03 -1.28925681e-03\n",
      "   6.55012464e-05]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(5,5, 1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    start = time.time()\n",
    "    ''' Implementing forward propagation'''\n",
    "    W1=parameters['W1'];\n",
    "    b1=parameters['b1'];\n",
    "    W2=parameters['W2'];\n",
    "    b2=parameters['b2'];\n",
    "#     print('Shape W1',W1.shape, 'W2 shape',W2.shape);\n",
    "    #Forward prop \n",
    "    Z1=np.dot(W1,X)+b1;\n",
    "#     A1=sigmoid(Z1);\n",
    "    A1=tangent_h(Z1);\n",
    "    Z2=np.dot(W2,A1)+b2;\n",
    "    A2=sigmoid(Z2);\n",
    "#     A2=tangent_h(Z2);\n",
    "#     print('A2 shape',A2.shape,' X.shape ',X.shape)\n",
    "    assert(A2.shape[1]== X.shape[1]);\n",
    "    end = time.time()\n",
    "#     print('Execution time for Forward Propagation',end - start)\n",
    "    return {'Z1':Z1,'A1':A1,'Z2':Z2,'A2':A2};\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2,Y):\n",
    "    '''Computing cost values for an iteration'''\n",
    "    start = time.time()\n",
    "    m=Y.shape[1];\n",
    "#     cost=(-1/m)* np.sum( np.multiply(np.log(A2),Y),np.multiply(np.log(1-A2),(1-Y)));\n",
    "#     cost=float(np.squeeze(cost));\n",
    "    \n",
    "#     m=Y_train.shape[1];\n",
    "    pt1=np.multiply(np.log(A2),Y)\n",
    "    pt2=np.multiply(np.log(1-A2),(1-Y))\n",
    "    cost=np.sum(pt1+pt2)*(-1/m)\n",
    "    cost=(np.squeeze(cost))\n",
    "    assert(isinstance(cost,float));\n",
    "    end = time.time()\n",
    "#     print('Execution time for Compute Cost',end - start)\n",
    "    return cost;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(cache,parameters,X,Y):\n",
    "    ''' Backward Propagation Implementation for the ANN'''\n",
    "    start = time.time()\n",
    "    m=X.shape[1];\n",
    "    W1=parameters['W1'];\n",
    "    b1=parameters['b1'];\n",
    "    W2=parameters['W2'];\n",
    "    b2=parameters['b2'];\n",
    "    \n",
    "    A1=cache['A1'];\n",
    "    A2=cache['A2'];\n",
    "    Z1=cache['Z1'];\n",
    "    \n",
    "    dz2=A2-Y;\n",
    "    dw2=(1/m)*np.dot(dz2,A1.T)\n",
    "    db2=(1/m)*(np.sum(dz2,axis=1,keepdims=True)) \n",
    "#     dz1=np.multiply (np.dot(W2.T,dz2),(sigmoid(Z1)*(1-sigmoid(Z1))));\n",
    "    dz1=np.multiply (np.dot(W2.T,dz2),(1-(np.power(np.tanh(Z1),2))));\n",
    "    dw1=(1/m)*np.dot(dz1,X.T);\n",
    "    db1=(1/m)* np.sum(dz1,axis=1,keepdims=True)\n",
    "    grads={'dw1':dw1,'db1':db1,'dw2':dw2,'db2':db2}    \n",
    "    end = time.time()\n",
    "#     print('Execution time for Backward Propagation',end - start)\n",
    "\n",
    "    return grads;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(grads,parameters,learning_rate):\n",
    "    '''Update the parameters '''\n",
    "    #parameters\n",
    "    start = time.time()\n",
    "    W1=parameters['W1'];\n",
    "    b1=parameters['b1'];\n",
    "    W2=parameters['W2'];\n",
    "    b2=parameters['b2'];\n",
    "    #grads\n",
    "    dw1=grads['dw1'];\n",
    "    dw2=grads['dw2'];\n",
    "    db1=grads['db1'];\n",
    "    db2=grads['db2'];\n",
    "    \n",
    "    #update \n",
    "    W1=W1 - (learning_rate*dw1);\n",
    "    b1=b1-(learning_rate*db1);\n",
    "    W2=W2-(learning_rate*dw2);\n",
    "    b2=b2-(learning_rate*db2);\n",
    "    \n",
    "    parameters={'W1':W1,'W2':W2,'b1':b1,'b2':b2};\n",
    "    end = time.time()\n",
    "#     print('Execution time for Update Parameters',end - start)\n",
    "\n",
    "    return parameters;\n",
    "    \n",
    "    \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model ( X,Y,n_h,num_iterations,learning_rate=0.001,print_cost=False):\n",
    "    '''Combining all the functions to generate a neural network.'''\n",
    "    n_x=X.shape[0]; # Since the matrix shape is nX,M where nX is the number of features and M is the number of examples.\n",
    "    n_y=Y.shape[0]; \n",
    "#     print(n_x,' ',n_y)\n",
    "    \n",
    "    #Initialize Parameters\n",
    "    parameters= initialize_parameters(n_x,n_h,n_y);\n",
    "    \n",
    "    \n",
    "    #Iteration Start (Gradient Descent)\n",
    "    for i in range(0,num_iterations):\n",
    "        start = time.time()\n",
    "        #Forward Propagation\n",
    "        cache = forward_propagation(X,parameters);\n",
    "#         print('A2', cache['A2'])\n",
    "#         print('Y',Y)\n",
    "        cost= compute_cost(cache['A2'],Y); # Generates the cost \n",
    "        #Do Backward Propagation\n",
    "        grads= backward_propagation(cache,parameters,X,Y);\n",
    "        #Update Weights.\n",
    "        parameters=update_parameters(grads,parameters,learning_rate);\n",
    "        end = time.time()\n",
    "#     print('Execution time for One Iteration',end - start)\n",
    "#         if print_cost  and  i%1000==0:\n",
    "        print('Cost',cost)\n",
    "        print(\"Cost after iteration %i : %f\"%(i,cost));\n",
    "        \n",
    "    return parameters;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters,X):\n",
    "    cache=forward_propagation(X,parameters);\n",
    "    A2=cache['A2'];\n",
    "    predictions=np.where(A2>=0.5,1,0);\n",
    "    return predictions;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape  (19200, 22500)\n",
      "X train shape  (1, 22500)\n"
     ]
    }
   ],
   "source": [
    "data_train.shape\n",
    "\n",
    "X_train=data_train.T.iloc[:,:-1].T.to_numpy()\n",
    "Y_train=data_train.T.iloc[:,-1].to_numpy()\n",
    "Y_train=Y_train.reshape((1,Y_train.shape[0]))\n",
    "print('X train shape ',X_train.shape)\n",
    "print('X train shape ',Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X validation shape  (19200, 2500)\n",
      "X validation shape  (1, 2500)\n"
     ]
    }
   ],
   "source": [
    "data_validation.shape\n",
    "\n",
    "X_validation=data_validation.T.iloc[:,:-1].T.to_numpy()\n",
    "Y_validation=data_validation.T.iloc[:,-1].to_numpy()\n",
    "Y_validation=Y_validation.reshape((1,Y_validation.shape[0]))\n",
    "print('X validation shape ',X_validation.shape)\n",
    "print('X validation shape ',Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parameters=nn_model(X_train,Y_train.T,5,10000,0.3,True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0 : 0.693146\n",
      "Execution time for 1000 Iteration 1.5956096649169922\n",
      "Cost after iteration 1000 : 0.638728\n",
      "Execution time for 1000 Iteration 876.2019281387329\n",
      "Cost after iteration 2000 : 0.630216\n",
      "Execution time for 1000 Iteration 809.2567977905273\n",
      "Cost after iteration 3000 : 0.613707\n",
      "Execution time for 1000 Iteration 814.0228354930878\n",
      "Cost after iteration 4000 : 0.591161\n",
      "Execution time for 1000 Iteration 807.3985114097595\n",
      "Cost after iteration 5000 : 0.607249\n",
      "Execution time for 1000 Iteration 781.5039131641388\n",
      "Cost after iteration 6000 : 0.577309\n",
      "Execution time for 1000 Iteration 821.5877752304077\n",
      "Cost after iteration 7000 : 0.590434\n",
      "Execution time for 1000 Iteration 769.5549182891846\n",
      "Cost after iteration 8000 : 0.593967\n",
      "Execution time for 1000 Iteration 768.3112406730652\n",
      "Cost after iteration 9000 : 0.549837\n",
      "Execution time for 1000 Iteration 708.1844613552094\n"
     ]
    }
   ],
   "source": [
    "n_x=X_train.shape[0]; # Since the matrix shape is nX,M where nX is the number of features and M is the number of examples.\n",
    "n_y=Y_train.shape[0]; \n",
    "n_h=10;\n",
    "parameters= initialize_parameters(n_x,n_h,n_y);\n",
    "start = time.time()\n",
    "for i in range(0,10000):\n",
    "    cache = forward_propagation(X_train,parameters);\n",
    "    # cache['A1'].shape\n",
    "    cost= compute_cost(cache['A2'],Y_train); # Generates the cost \n",
    "#     print('Cost',cost)\n",
    "    grads= backward_propagation(cache,parameters,X_train,Y_train);\n",
    "    parameters=update_parameters(grads,parameters,0.3);\n",
    "    if i%1000==0:\n",
    "        end = time.  time()\n",
    "        print(\"Cost after iteration %i : %f\"%(i,cost));\n",
    "        print('Execution time for 1000 Iteration',end - start)\n",
    "        start=time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 59.52 %\n"
     ]
    }
   ],
   "source": [
    "cache=forward_propagation(X_validation,parameters);\n",
    "A2=cache['A2'];\n",
    "y_validation_predictions=np.where(A2>=0.5,1,0);\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_validation_predictions - Y_validation)) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
